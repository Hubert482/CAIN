{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWpo9q7lkR8X"
      },
      "source": [
        "# Check gpu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IabsZDECZCDg",
        "outputId": "99a6dabf-9508-46f1-8a12-0981f59b96aa"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Mar 13 09:26:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqA5RLmRkdRN"
      },
      "source": [
        "# Clone the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEobV2KCMX3H",
        "outputId": "3fe7118f-5480-43bf-c826-d221900c44b3"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/Hubert482/CAIN.git"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'CAIN'...\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 141 (delta 76), reused 96 (delta 40), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (141/141), 6.14 MiB | 41.36 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcbScG0ATZOG"
      },
      "source": [
        "# connect to gdrive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLr2TQ5nTg-v",
        "outputId": "7c6d9fbe-e93c-42ae-fa0e-25e45697b8d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riIpSmo0khQA"
      },
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc2SKi9_MpRl",
        "outputId": "d7bcdf60-8753-4b45-c5d8-01c155bb2fbf"
      },
      "source": [
        "pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckjVBAKGlMWB"
      },
      "source": [
        "# generate  DataSet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzQKHeejjjNL",
        "cellView": "form"
      },
      "source": [
        "#@markdown Folder path with all the videos\n",
        "inputPath = \"/content/gdrive/MyDrive/Dataset_videos/\" #@param{type:\"string\"}\n",
        "#@markdown Path to generate the Dataset\n",
        "outputPath = \"/content/CAIN/data/vimeo_triplet/\" #@param{type:\"string\"}\n",
        "#@markdown The bigger the value, the more alike the frames need to be to be considered a triplet.\n",
        "psnr = 25 #@param{type:\"number\"}\n",
        "global  outputPath\n",
        "#@markdown resize to 448x256\n",
        "resize = True #@param{type:\"boolean\"}\n",
        "\n",
        "#Original dataset information:\n",
        "#Vimeo-90K triplets dataset contains 91701 triplets extracted from 15k video clips.\n",
        "#Each triplet is a short RGB video sequence that consists of 3 frames with fixed resolution 448x256\n",
        "\n",
        "\n",
        "def calculate_psnr(img1, img2, max_value=255):\n",
        "    \"\"\"\"Calculating peak signal-to-noise ratio (PSNR) between two images.\"\"\"\n",
        "    i1 = PIL.Image.open(img1).convert('RGB')\n",
        "    i2 = PIL.Image.open(img2).convert('RGB')\n",
        "\n",
        "    mse = np.mean((np.array(i1, dtype=np.float32) - np.array(i2, dtype=np.float32)) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * np.log10(max_value / (np.sqrt(mse)))\n",
        "\n",
        "\n",
        "def IsDiffScenes(img1, img2, diff=25):\n",
        "  return calculate_psnr(img1, img2) <= diff\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import time\n",
        "import PIL\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "if not os.path.isdir(outputPath):\n",
        "  os.makedirs(outputPath)\n",
        "\n",
        "if not os.path.isdir(outputPath + \"sequences\"):\n",
        "  os.makedirs(outputPath + \"sequences\")\n",
        "\n",
        "counter = 1\n",
        "for video in sorted(os.listdir(inputPath)):\n",
        "  temp = \"/content/.temp/\"\n",
        "  path = inputPath + video\n",
        "  if os.path.isdir(temp):\n",
        "    shutil.rmtree(temp)\n",
        "    #time.sleep(2)\n",
        "  os.makedirs(temp)\n",
        "\n",
        "  rescale = \"\"\n",
        "  if resize:\n",
        "    rescale=\"scale=448:256,\"\n",
        "  !ffmpeg -i \"{path}\" -vf \"{rescale}mpdecimate\" -vsync 0 -qscale:v 1 -pix_fmt rgb24  \"{temp}%10d.png\"\n",
        "\n",
        "  root =outputPath + \"/sequences/\" + str(counter).zfill(3) + \"/\"\n",
        "  if not os.path.isdir(root):\n",
        "    os.makedirs(root)\n",
        "\n",
        "\n",
        "  triIndex = 1\n",
        "  images = sorted(os.listdir(temp))\n",
        "  for i in range(2, len(images)) :\n",
        "    im1 = temp + images[i-2]\n",
        "    im2 =  temp + images[i-1]\n",
        "    im3 =  temp + images[i]\n",
        "    if IsDiffScenes(im1, im2, psnr) == False and IsDiffScenes(im2, im3, psnr) == False:\n",
        "      #print(\"Triplet Found\")\n",
        "      triPath = root + str(triIndex).zfill(5) + \"/\"\n",
        "      if not os.path.isdir(triPath):\n",
        "        os.makedirs(triPath)\n",
        "      copyfile(im1, triPath + \"im1.png\")\n",
        "      copyfile(im2, triPath + \"im2.png\")\n",
        "      copyfile(im3, triPath + \"im3.png\")\n",
        "      triIndex +=1\n",
        "\n",
        "  counter += 1\n",
        "\n",
        "testingPercentage = 0.1 #@param{type:\"slider\", min:0.1, max:0.9, step:0.1}\n",
        "database=outputPath\n",
        "import random\n",
        "\n",
        "if os.path.isfile(database + \"tri_testlist.txt\"):\n",
        "  os.remove(database + \"tri_testlist.txt\")\n",
        "if os.path.isfile(database + \"tri_trainlist.txt\"):\n",
        "  os.remove(database + \"tri_trainlist.txt\")\n",
        "\n",
        "from glob import glob\n",
        "folders = glob(database + \"sequences/*/\")\n",
        "\n",
        "paths = []\n",
        "\n",
        "for i in range(0, len(folders)):\n",
        "  triplets = glob(folders[i] + \"/*/\")\n",
        "  for ii in range(0, len(triplets)):\n",
        "    innerF = os.path.basename((os.path.dirname(triplets[ii])))\n",
        "    outF = os.path.basename((os.path.dirname(folders[i])))\n",
        "    paths.append(outF + \"/\" + innerF)\n",
        "\n",
        "def partitionRankings(rawRatings, testPercent):\n",
        "    howManyNumbers = int(round(testPercent*len(rawRatings)))\n",
        "    shuffled = rawRatings[:]\n",
        "    random.shuffle(shuffled)\n",
        "    return shuffled[howManyNumbers:], shuffled[:howManyNumbers]\n",
        "\n",
        "training, test = partitionRankings(paths, testingPercentage)\n",
        "\n",
        "\n",
        "trainTxt = database + \"/tri_trainlist.txt\"\n",
        "trainFile = open(trainTxt, 'w')\n",
        "\n",
        "testTxt = database + \"/tri_testlist.txt\"\n",
        "testFile = open(testTxt, 'w')\n",
        "\n",
        "for txt in training:\n",
        "  trainFile.write(txt + \"\\n\")\n",
        "trainFile.close()\n",
        "\n",
        "for txt in test:\n",
        "  testFile.write(txt + \"\\n\")\n",
        "testFile.close()\n",
        "\n",
        "print(training)\n",
        "print(test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW8oBuAOnocP"
      },
      "source": [
        "# Train the model (This take a long time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksy78n0mNnW5"
      },
      "source": [
        "%cd /content/CAIN\n",
        "import os \n",
        "#@markdown model is save in your google drive (CAINMODEL/)\n",
        "\n",
        "dataset = \"/content/CAIN/data/vimeo_triplet/\" #@param{type:\"string\"}\n",
        "exp_name = \"exp/\" #@param{type:\"string\"}\n",
        "\n",
        "resume = False #@param{type:\"boolean\"}\n",
        "batch_size =  20 #@param{type:\"number\"}\n",
        "if resume==True:\n",
        "  resume=\"--resume\"\n",
        "\n",
        "!python main.py --colab --data_root \"{dataset}\" --batch_size {batch_size} --test_batch_size {batch_size} {resume} --exp_name \"{exp_name}\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}