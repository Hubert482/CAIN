{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWpo9q7lkR8X"
      },
      "source": [
        "# Check gpu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IabsZDECZCDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d550c0f8-06e3-41c9-ffd2-1db2b9643d7c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Mar 12 17:32:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqA5RLmRkdRN"
      },
      "source": [
        "# Clone the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEobV2KCMX3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456951c2-28fd-42a5-eb72-729f8ede8a6d"
      },
      "source": [
        "!git clone https://github.com/Hubert482/CAIN.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CAIN'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 126 (delta 66), reused 86 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (126/126), 6.12 MiB | 22.16 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcbScG0ATZOG"
      },
      "source": [
        "# connect to gdrive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLr2TQ5nTg-v",
        "outputId": "c2fe119b-ea49-4aee-eeee-0c8578af52b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riIpSmo0khQA"
      },
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc2SKi9_MpRl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "dd2f45a2-f960-4b93-c2ee-ccbd5c264991"
      },
      "source": [
        "pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckjVBAKGlMWB"
      },
      "source": [
        "# generate  DataSet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzQKHeejjjNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "1c615aab-ece6-4baa-e4a6-18a2d0467231"
      },
      "source": [
        "#@markdown Folder path with all the videos\n",
        "inputPath = \"/content/gdrive/MyDrive/Dataset_videos/\" #@param{type:\"string\"}\n",
        "#@markdown Path to generate the Dataset\n",
        "outputPath = \"/content/CAIN/data/vimeo_triplet/\" #@param{type:\"string\"}\n",
        "#@markdown The bigger the value, the more alike the frames need to be to be considered a triplet.\n",
        "psnr = 25 #@param{type:\"number\"}\n",
        "global  outputPath\n",
        "#@markdown resize to 448x256\n",
        "resize = True #@param{type:\"boolean\"}\n",
        "\n",
        "#Original dataset information:\n",
        "#Vimeo-90K triplets dataset contains 91701 triplets extracted from 15k video clips.\n",
        "#Each triplet is a short RGB video sequence that consists of 3 frames with fixed resolution 448x256\n",
        "\n",
        "\n",
        "def calculate_psnr(img1, img2, max_value=255):\n",
        "    \"\"\"\"Calculating peak signal-to-noise ratio (PSNR) between two images.\"\"\"\n",
        "    i1 = PIL.Image.open(img1).convert('RGB')\n",
        "    i2 = PIL.Image.open(img2).convert('RGB')\n",
        "\n",
        "    mse = np.mean((np.array(i1, dtype=np.float32) - np.array(i2, dtype=np.float32)) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * np.log10(max_value / (np.sqrt(mse)))\n",
        "\n",
        "\n",
        "def IsDiffScenes(img1, img2, diff=25):\n",
        "  return calculate_psnr(img1, img2) <= diff\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import time\n",
        "import PIL\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "if not os.path.isdir(outputPath):\n",
        "  os.makedirs(outputPath)\n",
        "\n",
        "if not os.path.isdir(outputPath + \"sequences\"):\n",
        "  os.makedirs(outputPath + \"sequences\")\n",
        "\n",
        "counter = 1\n",
        "for video in sorted(os.listdir(inputPath)):\n",
        "  temp = \"/content/.temp/\"\n",
        "  path = inputPath + video\n",
        "  if os.path.isdir(temp):\n",
        "    shutil.rmtree(temp)\n",
        "    #time.sleep(2)\n",
        "  os.makedirs(temp)\n",
        "\n",
        "  rescale = \"\"\n",
        "  if resize:\n",
        "    rescale=\"scale=448:-1,pad=ceil(iw/2)*2:256,\"\n",
        "  !ffmpeg -i \"{path}\" -vf \"{rescale}mpdecimate\" -vsync 0 -qscale:v 1 -pix_fmt rgb24  \"{temp}%10d.png\"\n",
        "\n",
        "  root =outputPath + \"/sequences/\" + str(counter).zfill(3) + \"/\"\n",
        "  if not os.path.isdir(root):\n",
        "    os.makedirs(root)\n",
        "\n",
        "\n",
        "  triIndex = 1\n",
        "  images = sorted(os.listdir(temp))\n",
        "  for i in range(2, len(images)) :\n",
        "    im1 = temp + images[i-2]\n",
        "    im2 =  temp + images[i-1]\n",
        "    im3 =  temp + images[i]\n",
        "    if IsDiffScenes(im1, im2, psnr) == False and IsDiffScenes(im2, im3, psnr) == False:\n",
        "      #print(\"Triplet Found\")\n",
        "      triPath = root + str(triIndex).zfill(5) + \"/\"\n",
        "      if not os.path.isdir(triPath):\n",
        "        os.makedirs(triPath)\n",
        "      copyfile(im1, triPath + \"im1.png\")\n",
        "      copyfile(im2, triPath + \"im2.png\")\n",
        "      copyfile(im3, triPath + \"im3.png\")\n",
        "      triIndex +=1\n",
        "\n",
        "  counter += 1\n",
        "\n",
        "testingPercentage = 0.1 #@param{type:\"slider\", min:0.1, max:0.9, step:0.1}\n",
        "database=outputPath\n",
        "import random\n",
        "\n",
        "if os.path.isfile(database + \"tri_testlist.txt\"):\n",
        "  os.remove(database + \"tri_testlist.txt\")\n",
        "if os.path.isfile(database + \"tri_trainlist.txt\"):\n",
        "  os.remove(database + \"tri_trainlist.txt\")\n",
        "\n",
        "from glob import glob\n",
        "folders = glob(database + \"sequences/*/\")\n",
        "\n",
        "paths = []\n",
        "\n",
        "for i in range(0, len(folders)):\n",
        "  triplets = glob(folders[i] + \"/*/\")\n",
        "  for ii in range(0, len(triplets)):\n",
        "    innerF = os.path.basename((os.path.dirname(triplets[ii])))\n",
        "    outF = os.path.basename((os.path.dirname(folders[i])))\n",
        "    paths.append(outF + \"/\" + innerF)\n",
        "\n",
        "def partitionRankings(rawRatings, testPercent):\n",
        "    howManyNumbers = int(round(testPercent*len(rawRatings)))\n",
        "    shuffled = rawRatings[:]\n",
        "    random.shuffle(shuffled)\n",
        "    return shuffled[howManyNumbers:], shuffled[:howManyNumbers]\n",
        "\n",
        "training, test = partitionRankings(paths, testingPercentage)\n",
        "\n",
        "\n",
        "trainTxt = database + \"/tri_trainlist.txt\"\n",
        "trainFile = open(trainTxt, 'w')\n",
        "\n",
        "testTxt = database + \"/tri_testlist.txt\"\n",
        "testFile = open(testTxt, 'w')\n",
        "\n",
        "for txt in training:\n",
        "  trainFile.write(txt + \"\\n\")\n",
        "trainFile.close()\n",
        "\n",
        "for txt in test:\n",
        "  testFile.write(txt + \"\\n\")\n",
        "testFile.close()\n",
        "\n",
        "print(training)\n",
        "print(test)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.1 : 5.1\n",
            "\u001b[0mInput #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/gdrive/MyDrive/Dataset_videos/1.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:24.08, start: 0.000000, bitrate: 4020 kb/s\n",
            "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 3752 kb/s, 23.98 fps, 23.98 tbr, 27021 tbn, 47.95 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, 5.1, fltp, 360 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/.temp/%10d.png':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(eng): Video: png, rgb24, 448x256 [SAR 1:1 DAR 7:4], q=2-31, 200 kb/s, 23.98 fps, 23.98 tbn, 23.98 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame=  396 fps= 40 q=-0.0 Lsize=N/A time=00:00:23.44 bitrate=N/A speed=2.36x    \n",
            "video:59419kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "['001/00040', '001/00070', '001/00071', '001/00068', '001/00013', '001/00082', '001/00035', '001/00105', '001/00049', '001/00009', '001/00016', '001/00051', '001/00001', '001/00091', '001/00096', '001/00074', '001/00099', '001/00010', '001/00102', '001/00026', '001/00081', '001/00069', '001/00080', '001/00085', '001/00086', '001/00047', '001/00107', '001/00021', '001/00083', '001/00012', '001/00072', '001/00020', '001/00053', '001/00076', '001/00032', '001/00097', '001/00011', '001/00018', '001/00055', '001/00023', '001/00033', '001/00054', '001/00014', '001/00007', '001/00031', '001/00065', '001/00062', '001/00006', '001/00029', '001/00050', '001/00106', '001/00088', '001/00019', '001/00003', '001/00104', '001/00090', '001/00075', '001/00039', '001/00045', '001/00094', '001/00025', '001/00063', '001/00100', '001/00034', '001/00084', '001/00008', '001/00061', '001/00041', '001/00092', '001/00048', '001/00060', '001/00064', '001/00066', '001/00022', '001/00004', '001/00017', '001/00073', '001/00005', '001/00078', '001/00028', '001/00089', '001/00044', '001/00087', '001/00079', '001/00037', '001/00030', '001/00015', '001/00043', '001/00058', '001/00027', '001/00095', '001/00101', '001/00046', '001/00059', '001/00098', '001/00056']\n",
            "['001/00024', '001/00002', '001/00038', '001/00052', '001/00036', '001/00057', '001/00067', '001/00042', '001/00077', '001/00093', '001/00103']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW8oBuAOnocP"
      },
      "source": [
        "# Train the model (This take a long time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksy78n0mNnW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "cellView": "form",
        "outputId": "f11746f2-ad52-4fbc-b219-f62f51467dc5"
      },
      "source": [
        "%cd /content/CAIN\n",
        "import os \n",
        "#@markdown model is save in your google drive (CAINMODEL/)\n",
        "\n",
        "dataset = \"/content/CAIN/data/vimeo_triplet/\" #@param{type:\"string\"}\n",
        "\n",
        "resume = False #@param{type:\"boolean\"}\n",
        "batch_size =  20 #@param{type:\"number\"}\n",
        "\n",
        "\n",
        "import argparse\n",
        "\n",
        "arg_lists = []\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "def str2bool(v):\n",
        "    return v.lower() in ('true')\n",
        "\n",
        "def add_argument_group(name):\n",
        "    arg = parser.add_argument_group(name)\n",
        "    arg_lists.append(arg)\n",
        "    return arg\n",
        "\n",
        "# Dataset\n",
        "data_arg = add_argument_group('Dataset')\n",
        "data_arg.add_argument('--dataset', type=str, default='vimeo90k')\n",
        "data_arg.add_argument('--num_frames', type=int, default=3)\n",
        "data_arg.add_argument('--data_root', type=str, default=dataset)\n",
        "data_arg.add_argument('--img_fmt', type=str, default='png')\n",
        "\n",
        "# Model\n",
        "model_arg = add_argument_group('Model')\n",
        "model_arg.add_argument('--model', type=str, default='CAIN')\n",
        "model_arg.add_argument('--depth', type=int, default=3, help='# of pooling')\n",
        "model_arg.add_argument('--n_resblocks', type=int, default=12)\n",
        "model_arg.add_argument('--up_mode', type=str, default='shuffle')\n",
        "\n",
        "# Training / test parameters\n",
        "learn_arg = add_argument_group('Learning')\n",
        "learn_arg.add_argument('--mode', type=str, default='train',\n",
        "                       choices=['train', 'test', 'test-multi', 'gen-multi'])\n",
        "learn_arg.add_argument('--loss', type=str, default='1*L1')\n",
        "learn_arg.add_argument('--lr', type=float, default=1e-4)\n",
        "learn_arg.add_argument('--beta1', type=float, default=0.9)\n",
        "learn_arg.add_argument('--beta2', type=float, default=0.99)\n",
        "learn_arg.add_argument('--batch_size', type=int, default=batch_size)\n",
        "learn_arg.add_argument('--val_batch_size', type=int, default=batch_size)\n",
        "learn_arg.add_argument('--test_batch_size', type=int, default=batch_size)\n",
        "learn_arg.add_argument('--test_mode', type=str, default='hard', help='Test mode to evaluate on SNU-FILM dataset')\n",
        "learn_arg.add_argument('--start_epoch', type=int, default=0)\n",
        "learn_arg.add_argument('--max_epoch', type=int, default=200)\n",
        "learn_arg.add_argument('--resume', action='store_true', default=resume)\n",
        "learn_arg.add_argument('--resume_exp', type=str, default=None)\n",
        "learn_arg.add_argument('--fix_loaded', action='store_true', help='whether to fix updating all loaded parts of the model')\n",
        "\n",
        "# Misc\n",
        "misc_arg = add_argument_group('Misc')\n",
        "misc_arg.add_argument('--exp_name', type=str, default='exp')\n",
        "misc_arg.add_argument('--log_iter', type=int, default=1)\n",
        "misc_arg.add_argument('--log_dir', type=str, default='logs')\n",
        "misc_arg.add_argument('--data_dir', type=str, default='data')\n",
        "misc_arg.add_argument('--num_gpu', type=int, default=1)\n",
        "misc_arg.add_argument('--random_seed', type=int, default=12345)\n",
        "misc_arg.add_argument('--num_workers', type=int, default=5)\n",
        "misc_arg.add_argument('--use_tensorboard', action='store_true')\n",
        "misc_arg.add_argument('--viz', action='store_true', help='whether to save images')\n",
        "misc_arg.add_argument('--lpips', action='store_true', help='evaluates LPIPS if set true')\n",
        "\n",
        "def get_args():\n",
        "    \"\"\"Parses all of the arguments above\n",
        "    \"\"\"\n",
        "    args, unparsed = parser.parse_known_args()\n",
        "    if args.num_gpu > 0:\n",
        "        setattr(args, 'cuda', True)\n",
        "    else:\n",
        "        setattr(args, 'cuda', False)\n",
        "    if len(unparsed) > 1:\n",
        "        print(\"Unparsed args: {}\".format(unparsed))\n",
        "    return args, unparsed\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import utils\n",
        "from loss import Loss\n",
        "\n",
        "import threading\n",
        "modelname=\"2x_Hubert_HD\"\n",
        "##### Parse CmdLine Arguments #####\n",
        "args, unparsed = get_args()\n",
        "cwd = os.getcwd()\n",
        "print(args)\n",
        "\n",
        "\n",
        "##### TensorBoard & Misc Setup #####\n",
        "if args.mode != 'test':\n",
        "    writer = SummaryWriter('logs/%s' % args.exp_name)\n",
        "\n",
        "device = torch.device('cuda' if args.cuda else 'cpu')\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "torch.manual_seed(args.random_seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.random_seed)\n",
        "\n",
        "\n",
        "##### Load Dataset #####\n",
        "train_loader, test_loader = utils.load_dataset(\n",
        "    args.dataset, args.data_root, args.batch_size, args.test_batch_size, 1, args.test_mode)\n",
        "\n",
        "\n",
        "##### Build Model #####\n",
        "if args.model.lower() == 'cain_encdec':\n",
        "    from model.cain_encdec import CAIN_EncDec\n",
        "    print('Building model: CAIN_EncDec')\n",
        "    model = CAIN_EncDec(depth=args.depth, start_filts=32)\n",
        "elif args.model.lower() == 'cain':\n",
        "    from model.cain import CAIN\n",
        "    print(\"Building model: CAIN\")\n",
        "    model = CAIN(depth=args.depth)\n",
        "elif args.model.lower() == 'cain_noca':\n",
        "    from model.cain_noca import CAIN_NoCA\n",
        "    print(\"Building model: CAIN_NoCA\")\n",
        "    model = CAIN_NoCA(depth=args.depth)\n",
        "else:\n",
        "    raise NotImplementedError(\"Unknown model!\")\n",
        "# Just make every model to DataParallel\n",
        "model = torch.nn.DataParallel(model).to(device)\n",
        "#print(model)\n",
        "\n",
        "##### Define Loss & Optimizer #####\n",
        "criterion = Loss(args)\n",
        "\n",
        "args.radam = False\n",
        "if args.radam:\n",
        "    from radam import RAdam\n",
        "    optimizer = RAdam(model.parameters(), lr=args.lr, betas=(args.beta1, args.beta2))\n",
        "else:\n",
        "    from torch.optim import Adam\n",
        "    optimizer = Adam(model.parameters(), lr=args.lr, betas=(args.beta1, args.beta2))\n",
        "print('# of parameters: %d' % sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "\n",
        "# If resume, load checkpoint: model + optimizer\n",
        "if args.resume:\n",
        "    utils.load_checkpoint(args, model, optimizer)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "#torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
        "# Initialize LPIPS model if used for evaluation\n",
        "# lpips_model = utils.init_lpips_eval() if args.lpips else None\n",
        "lpips_model = None\n",
        "\n",
        "LOSS_0 = 0\n",
        "\n",
        "def train(args, epoch):\n",
        "    global startedpbar\n",
        "    startedpbar=0\n",
        "    global LOSS_0\n",
        "    losses, psnrs, ssims, lpips = utils.init_meters(args.loss)\n",
        "    model.train()\n",
        "    criterion.train()\n",
        "\n",
        "    t = time.time()\n",
        "\n",
        "    \n",
        "    for i, (images, imgpaths) in enumerate(train_loader):\n",
        "        #print(startedpbar)\n",
        "        if startedpbar==0:\n",
        "            pbar=tqdm(range(i, len(train_loader)))\n",
        "            startedpbar=1\n",
        "        else:\n",
        "            startedpbar=1\n",
        "            #print(startedpbar)\n",
        "        \n",
        "        # Build input batch\n",
        "        im1, im2, gt = utils.build_input(images, imgpaths)\n",
        "\n",
        "        # Forward\n",
        "        optimizer.zero_grad()\n",
        "        out, feats = model(im1, im2)\n",
        "        loss, loss_specific = criterion(out, gt, None, feats)\n",
        "\n",
        "        # Save loss values\n",
        "        for k, v in losses.items():\n",
        "            if k != 'total':\n",
        "                v.update(loss_specific[k].item())\n",
        "        if LOSS_0 == 0:\n",
        "            LOSS_0 = loss.data.item()\n",
        "        losses['total'].update(loss.item())\n",
        "\n",
        "        # Backward (+ grad clip) - if loss explodes, skip current iteration\n",
        "        loss.backward()\n",
        "        if loss.data.item() > 10.0 * LOSS_0:\n",
        "            print(max(p.grad.data.abs().max() for p in model.parameters()))\n",
        "            continue\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calc metrics & print logs\n",
        "        if i % args.log_iter == 0:\n",
        "            utils.eval_metrics(out, gt, psnrs, ssims, lpips, lpips_model)\n",
        "\n",
        "           #print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}\\tPSNR: {:.4f}\\tTime({:.2f})'.format(\n",
        "           #     epoch, i, len(train_loader), losses['total'].avg, psnrs.avg, time.time() - t))\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix({'psnr': psnrs.avg, 'Loss': losses['total'].avg, 'epoch': epoch })\n",
        "            # Log to TensorBoard\n",
        "            utils.log_tensorboard(writer, losses, psnrs.avg, ssims.avg, lpips.avg,\n",
        "                optimizer.param_groups[-1]['lr'], epoch * len(train_loader) + i)\n",
        "            # Reset metrics\n",
        "            losses, psnrs, ssims, lpips = utils.init_meters(args.loss)\n",
        "            t = time.time()\n",
        "\n",
        "\n",
        "def test(args, epoch, eval_alpha=0.5):\n",
        "    print('Evaluating for  %d' % epoch)\n",
        "    losses, psnrs, ssims, lpips = utils.init_meters(args.loss)\n",
        "    model.eval()\n",
        "    criterion.eval()\n",
        "\n",
        "    save_folder = 'test%03d' % epoch\n",
        "    if args.dataset == 'snufilm':\n",
        "        save_folder = os.path.join(save_folder, args.dataset, args.test_mode)\n",
        "    else:\n",
        "        save_folder = os.path.join(save_folder, args.dataset)\n",
        "    save_dir = os.path.join('checkpoint', args.exp_name, save_folder)\n",
        "    utils.makedirs(save_dir)\n",
        "    save_fn = os.path.join(save_dir, 'results.txt')\n",
        "    if not os.path.exists(save_fn):\n",
        "        with open(save_fn, 'w') as f:\n",
        "            f.write('For epoch=%d\\n' % epoch)\n",
        "\n",
        "    t = time.time()\n",
        "    def save():\n",
        "        utils.save_image(out[b], \"%s.png\" % fp)\n",
        "    with torch.no_grad():\n",
        "        for i, (images, imgpaths) in enumerate(tqdm(test_loader)):\n",
        "\n",
        "            # Build input batch\n",
        "            im1, im2, gt = utils.build_input(images, imgpaths, is_training=False)\n",
        "\n",
        "            # Forward\n",
        "            out, feats = model(im1, im2)\n",
        "\n",
        "            # Save loss values\n",
        "            loss, loss_specific = criterion(out, gt, None, feats)\n",
        "            for k, v in losses.items():\n",
        "                if k != 'total':\n",
        "                    v.update(loss_specific[k].item())\n",
        "            losses['total'].update(loss.item())\n",
        "\n",
        "            # Evaluate metrics\n",
        "            utils.eval_metrics(out, gt, psnrs, ssims, lpips)\n",
        "\n",
        "            # Log examples that have bad performance\n",
        "            if (ssims.val < 0.9 or psnrs.val < 25) and epoch > 50:\n",
        "                print(imgpaths)\n",
        "                print(\"\\nLoss: %f, PSNR: %f, SSIM: %f, LPIPS: %f\" %\n",
        "                      (losses['total'].val, psnrs.val, ssims.val, lpips.val))\n",
        "                print(imgpaths[1][-1])\n",
        "            # Save result images\n",
        "            if ((epoch + 1) % 1 == 0 and i < 20) or args.mode == 'test':\n",
        "                savepath = os.path.join('checkpoint', args.exp_name, save_folder)\n",
        "\n",
        "                for b in range(images[0].size(0)):\n",
        "                    paths = imgpaths[1][b].split('/')\n",
        "                    fp = os.path.join(savepath, paths[-3], paths[-2])\n",
        "                    if not os.path.exists(fp):\n",
        "                        os.makedirs(fp)\n",
        "                    # remove '.png' extension\n",
        "                    fp = os.path.join(fp, paths[-1][:-4])\n",
        "                    \n",
        "                    tsave = threading.Thread(target=save)\n",
        "                    tsave.start()\n",
        "                    \n",
        "    # Print progress\n",
        "    print('im_processed: {:d}/{:d} {:.3f}s   \\r'.format(i + 1, len(test_loader), time.time() - t))\n",
        "    print(\"Loss: %f, PSNR: %f, SSIM: %f, LPIPS: %f\\n\" %\n",
        "          (losses['total'].avg, psnrs.avg, ssims.avg, lpips.avg))\n",
        "\n",
        "    # Save psnr & ssim\n",
        "    save_fn = os.path.join('checkpoint', args.exp_name, save_folder, 'results.txt')\n",
        "    with open(save_fn, 'a') as f:\n",
        "        f.write(\"PSNR: %f, SSIM: %f, LPIPS: %f\\n\" %\n",
        "                (psnrs.avg, ssims.avg, lpips.avg))\n",
        "\n",
        "    # Log to TensorBoard\n",
        "    if args.mode != 'test':\n",
        "        utils.log_tensorboard(writer, losses, psnrs.avg, ssims.avg, lpips.avg,\n",
        "            optimizer.param_groups[-1]['lr'], epoch * len(train_loader) + i, mode='test')\n",
        "\n",
        "    return losses['total'].avg, psnrs.avg, ssims.avg, lpips.avg\n",
        "\n",
        "\n",
        "\"\"\" Entry Point \"\"\"\n",
        "def main(args):\n",
        "    if args.mode == 'test':\n",
        "        _, _, _, _ = test(args, args.start_epoch)\n",
        "        return\n",
        "\n",
        "    best_psnr = 0\n",
        "    for epoch in range(args.start_epoch, args.max_epoch):\n",
        "        # run training\n",
        "        train(args, epoch)\n",
        "\n",
        "        # run test\n",
        "        test_loss, psnr, _, _ = test(args, epoch)\n",
        "\n",
        "        # save checkpoint\n",
        "        is_best = psnr > best_psnr\n",
        "        best_psnr = max(psnr, best_psnr)\n",
        "        utils.save_checkpoint({\n",
        "            'epoch': epoch,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'best_psnr': best_psnr,\n",
        "            'model_name': modelname\n",
        "        }, is_best, \"../../gdrive/MyDrive/CAINMODEL\")\n",
        "\n",
        "        # update optimizer policy\n",
        "        scheduler.step(test_loss)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(args)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5bf48cd97d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-d5bf48cd97d1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m'best_psnr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_psnr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;34m'model_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         }, is_best, \"../../gdrive/MyDrive/CAINMODEL\")\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# update optimizer policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CAIN/utils.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(state, is_best, exp_name, filename)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_best\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoint/%s/'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model_best.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}